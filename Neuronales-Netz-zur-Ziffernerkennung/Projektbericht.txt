============================================================
ğŸ“„ PROJEKTBERICHT â€“ Ziffernerkennung mit Neuronalen Netzen
============================================================

ğŸ—“ï¸ Datum:             26.07.2025
ğŸ‘© Autorin:           Heike Fasold
ğŸ’» Projektname:       Neuronales Netz zur Ziffernerkennung
ğŸ“‚ Quelle:            Projektarbeit-AI-Developement.py

------------------------------------------------------------
ğŸ§  MODELLARCHITEKTUR
------------------------------------------------------------
Eingabeschicht:       784 Neuronen (28x28 Bildpixel)
Verborgene Schicht:   300 Neuronen
Ausgabeschicht:       10 Neuronen (Ziffern 0â€“9)
Aktivierungsfunktion: Sigmoid
Verlustfunktion:      Mean Squared Error (MSE)
Optimierung:          Stochastic Gradient Descent (SGD)

------------------------------------------------------------
ğŸ“Š TRAININGSKONFIGURATION
------------------------------------------------------------
Trainingsdaten:       56.000 Bilder
Testdaten:            14.000 Bilder
Epochen:              5
Batch-GrÃ¶ÃŸe:          32
Lernrate:             0.5
Initialisierung:      Gleichverteilung [-0.5, 0.5]
Zufallsstartwert:     42

------------------------------------------------------------
ğŸ“ˆ TRAININGSERGEBNISSE (Letzte Epoche)
------------------------------------------------------------
Verlust (MSE):        0.014527
Genauigkeit:          93.25 %

------------------------------------------------------------
ğŸ–¼ï¸ GENERIERTE VISUALISIERUNGEN
------------------------------------------------------------
âœ“ Fehlerkurve (loss_curve.png)
âœ“ Genauigkeitskurve (accuracy_curve.png)
âœ“ Gewichtsmatrix (weights_matrix.png)
âœ“ Heatmap falsch klassifizierter Ziffern (heatmap_fehler/)
âœ“ Confusion-Matrix (confusion_heatmap.png)
âœ“ Beispielbilder mit Label-Overlay (mnist_bsp_train_labeled/*.png)

------------------------------------------------------------
ğŸ“ ABSCHLUSS
------------------------------------------------------------
Das entwickelte Feedforward-Netz erzielt eine solide Erkennungsrate auf dem
MNIST-Datensatz â€“ ohne Deep-Learning-Frameworks. Die Implementierung in reinem
NumPy ermÃ¶glicht ein tiefes VerstÃ¤ndnis der mathematischen Grundlagen neuronaler
Netze. Erweiterungsideen: CNN, EMNIST-Zeichen, Data Augmentation, PyTorch-Vergleich.

================================================================================
